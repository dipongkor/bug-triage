{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from keras.metrics import TopKCategoricalAccuracy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from losses import categorical_focal_loss\n",
    "from plot_keras_history import plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.metrics import TopKCategoricalAccuracy\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Dataset/mozilla_firefox.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Description</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>Dialup properties needs to be exposed in prefs</td>\n",
       "      <td>The dialup properties of the profile should be...</td>\n",
       "      <td>dialup properties needs to be exposed in prefs...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>[Find] Find whole word only</td>\n",
       "      <td>Please add \"Match Whole Word Only\" option to b...</td>\n",
       "      <td>find find whole word only. please add match wh...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>Plug-In Manager (ui for choosing mimetype-plug...</td>\n",
       "      <td>I would really like a plug-in manager for my b...</td>\n",
       "      <td>plugin manager ui for choosing mimetypeplugin ...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>add font-list support  to the font pref front end</td>\n",
       "      <td>Subject: Re: font selection interface\\nFrom: J...</td>\n",
       "      <td>add fontlist support to the font pref front en...</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nobody@mozilla.org</td>\n",
       "      <td>Ctrl-Alt-T to show networking debug info</td>\n",
       "      <td>This is a 4.x farity feature request, it is us...</td>\n",
       "      <td>ctrlaltt to show networking debug info. this i...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Assignee                                            Summary  \\\n",
       "0  nobody@mozilla.org     Dialup properties needs to be exposed in prefs   \n",
       "1  nobody@mozilla.org                        [Find] Find whole word only   \n",
       "2  nobody@mozilla.org  Plug-In Manager (ui for choosing mimetype-plug...   \n",
       "3  nobody@mozilla.org  add font-list support  to the font pref front end   \n",
       "4  nobody@mozilla.org           Ctrl-Alt-T to show networking debug info   \n",
       "\n",
       "                                         Description  \\\n",
       "0  The dialup properties of the profile should be...   \n",
       "1  Please add \"Match Whole Word Only\" option to b...   \n",
       "2  I would really like a plug-in manager for my b...   \n",
       "3  Subject: Re: font selection interface\\nFrom: J...   \n",
       "4  This is a 4.x farity feature request, it is us...   \n",
       "\n",
       "                                                text  words  \n",
       "0  dialup properties needs to be exposed in prefs...     63  \n",
       "1  find find whole word only. please add match wh...     19  \n",
       "2  plugin manager ui for choosing mimetypeplugin ...     92  \n",
       "3  add fontlist support to the font pref front en...    132  \n",
       "4  ctrlaltt to show networking debug info. this i...     49  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'Assignee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_developers = df[label_name].unique()\n",
    "developer_dict = {}\n",
    "for idx, developer in enumerate(unique_developers, start = 1):\n",
    "  developer_dict[developer] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[label_name] = df[label_name].astype(str).map(developer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_components = 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'].values\n",
    "Y = df[label_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_encoded = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [TopKCategoricalAccuracy(i+1, name=f'{i+1}') for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.full(df[label_name].nunique(), 0.25)\n",
    "loss = [categorical_focal_loss(alpha=[alpha], gamma=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn2_cnn3_model(summary, vocab_size, MAX_SEQUENCE_LENGTH):\n",
    "    input1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "    input2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "    \n",
    "    #CNN2\n",
    "    embed2 = Embedding(vocab_size, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(input1)\n",
    "    cnv2 = Conv1D(256, 2, activation=\"relu\")(embed2)\n",
    "    pool2 = MaxPooling1D(int(MAX_SEQUENCE_LENGTH * 0.2))(cnv2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    #CNN3\n",
    "    embed3 = Embedding(vocab_size, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(input2)\n",
    "    cnv3 = Conv1D(256, 3, activation=\"relu\")(embed3)\n",
    "    pool3 = MaxPooling1D(int(MAX_SEQUENCE_LENGTH * 0.2))(cnv3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    #Merge\n",
    "    merged = concatenate([flat2, flat3])\n",
    "    \n",
    "    dense2 = Dense(1024, activation=\"relu\")(merged)\n",
    "    \n",
    "    outputs = Dense(df[label_name].nunique(), activation='softmax')(dense2)\n",
    "    \n",
    "    model = Model(inputs=[input1, input2], outputs=outputs)\n",
    "    \n",
    "    model.compile(loss=loss, optimizer='rmsprop', metrics=metrics)\n",
    "    \n",
    "    if summary==True:\n",
    "        print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=101)\n",
    "cvscores = []\n",
    "histories = []\n",
    "miss_classified = []\n",
    "fold_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in kfold.split(X, Y):\n",
    "    \n",
    "    x_train = X[train]\n",
    "    x_test = X[test]\n",
    "    \n",
    "    y_train = Y_encoded[train]\n",
    "    y_test = Y_encoded[test]\n",
    "    \n",
    "    #Tokenizing & Padding\n",
    "    tokenizer = Tokenizer(oov_token=True)\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "    test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "    MAX_SEQUENCE_LENGTH = max([len(s) for s in train_seq])\n",
    "    train_cnn = pad_sequences(train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    test_cnn = pad_sequences(test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    \n",
    "    #Model Traing\n",
    "    model = cnn2_cnn3_model(False, vocab_size, MAX_SEQUENCE_LENGTH)\n",
    "    history = model.fit([train_cnn, train_cnn], y_train, epochs=5, validation_data = ([test_cnn, test_cnn], y_test), batch_size=32, verbose=0).history\n",
    "    \n",
    "    #Training History\n",
    "    pred = model.predict([test_cnn, test_cnn]) \n",
    "    actual_developers = np.argmax(y_test, axis=-1)\n",
    "    train_developers =  np.argmax(y_train, axis=-1)\n",
    "    pred_developers = np.argmax(pred, axis=-1)\n",
    "    miss = {'fold': fold_no, 'train_documents': train, 'train_developers': train_developers ,'test_documents': test, 'test_developers': actual_developers, 'pred_developers': pred_developers}\n",
    "    miss_classified.append(miss)\n",
    "    histories.append(history)\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    #Scores\n",
    "    scores = model.evaluate([test_cnn, test_cnn], y_test, batch_size=32, verbose=1)\n",
    "    cvscores.append(scores[1:])\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88560949, 0.94713293, 0.97075442, 0.97654976, 0.97941073,\n",
       "       0.98148922, 0.98278522, 0.9841301 , 0.98491259, 0.98540165])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cvscores).sum(axis=0)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in miss_classified:\n",
    "    for key in item.keys():\n",
    "        if isinstance(item[key], np.ndarray):\n",
    "            item[key] = item[key].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in histories:\n",
    "    for key in item.keys():\n",
    "        if key in history_dic.keys():\n",
    "            history_dic[key] = history_dic[key] + np.array(item[key])\n",
    "        else:\n",
    "            history_dic[key] = np.array(item[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_dic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(o):\n",
    "    if isinstance(o, np.int64): return int(o)  \n",
    "    raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history_dic.keys():\n",
    "    history_dic[key] = history_dic[key].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cnn2_cnn3_history.json', mode='w') as history_file:\n",
    "    json.dump(history_dic, history_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cnn2_cnn3_classification_report.json', 'w') as report_file:\n",
    "  json.dump(miss_classified, report_file, default=convert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
